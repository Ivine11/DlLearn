# 智能计算机应用基础

人工智能—机器学习—神经网络--深度学习

#### 机器学习

##### 符号说明

输入x， 真实y， 预测值y^， 模型函数H(x)， 激活函数G(x), 损失函数L(x)

标量：斜体小写， 向量：黑斜体小写，矩阵：黑斜体大写

### 神经网络

#### 神经网络结构

输入层+隐层+输出层

#### 激活函数

##### sigmoid函数

1/（1+e^(-x))。能够把输入连续实值变换为0–1，

缺点：

产生输出的均值非0

饱和性问题和梯度消失现象

计算机进行指数运算速度慢

##### tanh函数

$$(e^x - e^{-x})/(e^x + e^{-x})$$

tanh 均值为0， 在输入很大或很小时，输出几乎平滑， 梯度小， 不利于权重更新

缺点：梯度消失

##### RELU函数：

max（0， x)

relu在x<0时不激活

##### Leakly Relu：

max(ax, x) , 0<a<1

##### ELU:

x>0, x

x<=0, $\alpha(e^x-1)$

#### 损失函数

均方差损失函数

$$(y-y^x)^2/2$$

缺陷：均方差损失函数+sigmoid函数可能会出现梯度消失

##### 交叉熵损失函数：

![image-20220901142402054](/Users/pengruiying/Desktop/github/DlLearn/assets/image-20220901142402054.png)

二分类交叉损失函数：

![image-20220901142428059](/Users/pengruiying/Desktop/github/DlLearn/assets/image-20220901142428059.png)

##### 过拟合：

可能的原因：训练考虑的维度太多，使得拟合的函数很完美的接近训练数据集，但

##### 欠拟合：

训练考虑的维度太少

##### 防止过拟合：

参数范数惩罚，Bagging集成，Droupout，提前终止，数据集扩增

##### 参数范数惩罚：

![image-20220901143200286](/Users/pengruiying/Desktop/github/DlLearn/assets/image-20220901143200286.png)

![image-20220901143216276](/Users/pengruiying/Desktop/github/DlLearn/assets/image-20220901143216276.png)

在损失函数里加了权重矩阵wn，防止权重矩阵过大，降低网络复杂度

